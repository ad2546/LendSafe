{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dn8z3p4AwtFG"
      },
      "source": [
        "# LendSafe: Fine-tune Granite Model on Google Colab\n",
        "\n",
        "This notebook fine-tunes IBM Granite 4.0 H 350M for loan explanation generation.\n",
        "\n",
        "**Setup:**\n",
        "1. Runtime ‚Üí Change runtime type ‚Üí GPU (T4 is fine)\n",
        "2. Run all cells in order\n",
        "3. Download the fine-tuned model at the end"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eFOD5wPqwtFH"
      },
      "source": [
        "## 1. Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p2ZeppMHwtFI"
      },
      "outputs": [],
      "source": [
        "!pip install -q torch transformers accelerate peft datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ezJiz7LlwtFI"
      },
      "source": [
        "## 2. Upload Training Data\n",
        "\n",
        "Upload your `training_examples.jsonl` file from the LendSafe project."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "K2Lhz9rowtFI",
        "outputId": "10e9ed27-6c83-4301-c3dd-65604cc5c395"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üì§ Upload your training_examples.jsonl file\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-56ff2176-8460-4581-bf18-89d858c8e461\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-56ff2176-8460-4581-bf18-89d858c8e461\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚ùå Please upload training_examples.jsonl\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "import os\n",
        "\n",
        "print(\"üì§ Upload your training_examples.jsonl file\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Verify upload\n",
        "if 'training_examples.jsonl' in uploaded:\n",
        "    print(\"‚úÖ Training data uploaded successfully!\")\n",
        "    print(f\"   File size: {len(uploaded['training_examples.jsonl']) / 1024:.1f} KB\")\n",
        "else:\n",
        "    print(\"‚ùå Please upload training_examples.jsonl\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zwKgemxNwtFI"
      },
      "source": [
        "## 3. Load Model and Configure LoRA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lyPPR7xZwtFJ",
        "outputId": "b78d0d01-3845-4e3b-95ea-cbdf058c3990"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîß Configuration\n",
            "‚úÖ Using device: cuda\n",
            "   GPU: Tesla T4\n",
            "   Memory: 15.8 GB\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments, Trainer, DataCollatorForLanguageModeling\n",
        "from peft import LoraConfig, get_peft_model\n",
        "from datasets import load_dataset\n",
        "\n",
        "print(\"üîß Configuration\")\n",
        "MODEL_ID = \"ibm-granite/granite-4.0-h-350m\"\n",
        "MAX_LENGTH = 256\n",
        "BATCH_SIZE = 1  # GPU can handle more\n",
        "GRADIENT_ACCUMULATION = 2\n",
        "LEARNING_RATE = 2e-4\n",
        "NUM_EPOCHS = 3\n",
        "\n",
        "# Check GPU\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"‚úÖ Using device: {device}\")\n",
        "if device == \"cuda\":\n",
        "    print(f\"   GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"   Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j2QbFEO2wtFJ",
        "outputId": "6a00425d-25a4-405a-cf1e-20c27701cfb6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üì• Loading IBM Granite 350M model...\n",
            "‚úÖ Model loaded: 340,332,224 parameters\n"
          ]
        }
      ],
      "source": [
        "# Load model and tokenizer\n",
        "print(\"üì• Loading IBM Granite 350M model...\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID, trust_remote_code=True)\n",
        "\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    MODEL_ID,\n",
        "    torch_dtype=torch.float16,\n",
        "    device_map=\"auto\",\n",
        "    trust_remote_code=True\n",
        ")\n",
        "\n",
        "print(f\"‚úÖ Model loaded: {model.num_parameters():,} parameters\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b8f4nxxewtFJ",
        "outputId": "1339d998-f3f2-4b5e-86f1-26040d2016c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîß Configuring LoRA...\n",
            "‚úÖ LoRA configured:\n",
            "   Trainable params: 163,840 (0.05%)\n",
            "   Total params: 340,496,064\n"
          ]
        }
      ],
      "source": [
        "# Configure LoRA\n",
        "print(\"üîß Configuring LoRA...\")\n",
        "lora_config = LoraConfig(\n",
        "    r=8,\n",
        "    lora_alpha=16,\n",
        "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"],\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\"\n",
        ")\n",
        "\n",
        "model = get_peft_model(model, lora_config)\n",
        "\n",
        "trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "total = sum(p.numel() for p in model.parameters())\n",
        "print(f\"‚úÖ LoRA configured:\")\n",
        "print(f\"   Trainable params: {trainable:,} ({100*trainable/total:.2f}%)\")\n",
        "print(f\"   Total params: {total:,}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q1YmtCyrwtFJ"
      },
      "source": [
        "## 4. Prepare Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103,
          "referenced_widgets": [
            "73d32eca88c541ffbb59a0e944771f4d",
            "5ec04eecb2ef4681801ee1a329e5b21f",
            "4c7ad38cb98349ad918f3b5b1a159813",
            "2ccdf7a83bc14926928acfa50018fae2",
            "1c89705ecd8344c48f57369046aaf647",
            "920f9a09aaae4e29be51ebee8d689925",
            "ab6a4a3a8a8343c381586467c8824e0a",
            "efd45863c32a4aa7a8a13b4c1d0a0145",
            "0e9bd3352b014501aa0e37ae4d0cfd4e",
            "715dacc33545419288ae2f457e7c344e",
            "a04625562e5c4584bda15fa41afe6655"
          ]
        },
        "id": "ip8wy066wtFJ",
        "outputId": "69f54044-935f-4a6b-a314-bf67f8255ac0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìä Loading training data...\n",
            "‚úÖ Loaded 1500 examples\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1500 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "73d32eca88c541ffbb59a0e944771f4d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Train: 1350, Val: 150\n"
          ]
        }
      ],
      "source": [
        "# Load dataset\n",
        "print(\"üìä Loading training data...\")\n",
        "dataset = load_dataset('json', data_files='training_examples.jsonl', split='train')\n",
        "print(f\"‚úÖ Loaded {len(dataset)} examples\")\n",
        "\n",
        "# Format prompts\n",
        "def format_prompt(example):\n",
        "    prompt = f\"\"\"### Instruction:\n",
        "{example['instruction']}\n",
        "\n",
        "### Input:\n",
        "{example['input']}\n",
        "\n",
        "### Response:\n",
        "{example['output']}\"\"\"\n",
        "    return {\"text\": prompt}\n",
        "\n",
        "dataset = dataset.map(format_prompt, remove_columns=dataset.column_names)\n",
        "\n",
        "# Tokenize\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(\n",
        "        examples[\"text\"],\n",
        "        truncation=True,\n",
        "        max_length=MAX_LENGTH,\n",
        "        padding=\"max_length\"\n",
        "    )\n",
        "\n",
        "tokenized_dataset = dataset.map(\n",
        "    tokenize_function,\n",
        "    batched=True,\n",
        "    remove_columns=[\"text\"]\n",
        ")\n",
        "\n",
        "# Split\n",
        "split_dataset = tokenized_dataset.train_test_split(test_size=0.1, seed=42)\n",
        "print(f\"‚úÖ Train: {len(split_dataset['train'])}, Val: {len(split_dataset['test'])}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35sAArA3wtFK"
      },
      "source": [
        "## 5. Train Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "29sUC_VkwtFK",
        "outputId": "b1fa43d8-5b31-491a-85e8-7bd39fca4c19"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The model is already on multiple devices. Skipping the move to device specified in `args`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üöÄ Starting training...\n",
            "‚è∞ Expected time: 15-30 minutes on T4 GPU\n"
          ]
        }
      ],
      "source": [
        "# Training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./granite-finetuned\",\n",
        "    num_train_epochs=NUM_EPOCHS,\n",
        "    per_device_train_batch_size=BATCH_SIZE,\n",
        "    per_device_eval_batch_size=BATCH_SIZE,\n",
        "    gradient_accumulation_steps=GRADIENT_ACCUMULATION,\n",
        "    learning_rate=LEARNING_RATE,\n",
        "    fp16=True,\n",
        "    logging_steps=20,\n",
        "    eval_strategy=\"steps\",\n",
        "    eval_steps=100,\n",
        "    save_strategy=\"steps\",\n",
        "    save_steps=100,\n",
        "    save_total_limit=2,\n",
        "    warmup_steps=50,\n",
        "    load_best_model_at_end=True,\n",
        "    report_to=\"none\"\n",
        ")\n",
        "\n",
        "# Data collator\n",
        "data_collator = DataCollatorForLanguageModeling(\n",
        "    tokenizer=tokenizer,\n",
        "    mlm=False\n",
        ")\n",
        "\n",
        "# Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=split_dataset[\"train\"],\n",
        "    eval_dataset=split_dataset[\"test\"],\n",
        "    data_collator=data_collator,\n",
        ")\n",
        "\n",
        "print(\"üöÄ Starting training...\")\n",
        "print(\"‚è∞ Expected time: 15-30 minutes on T4 GPU\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 792
        },
        "id": "-NWxe1mDwtFK",
        "outputId": "f85b021c-51b3-4183-aefc-e4bec38567a8"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2025' max='2025' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2025/2025 3:02:39, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.615600</td>\n",
              "      <td>0.508336</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.385900</td>\n",
              "      <td>0.379051</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.365900</td>\n",
              "      <td>0.369811</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.360600</td>\n",
              "      <td>0.365230</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.362100</td>\n",
              "      <td>0.362569</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.364600</td>\n",
              "      <td>0.359952</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.357000</td>\n",
              "      <td>0.361346</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.347200</td>\n",
              "      <td>0.358096</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.346300</td>\n",
              "      <td>0.352499</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.348000</td>\n",
              "      <td>0.352406</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.348400</td>\n",
              "      <td>0.349150</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.341000</td>\n",
              "      <td>0.347471</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>0.343800</td>\n",
              "      <td>0.345109</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.339500</td>\n",
              "      <td>0.343703</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.337100</td>\n",
              "      <td>0.339986</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.337900</td>\n",
              "      <td>0.340150</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1700</td>\n",
              "      <td>0.343100</td>\n",
              "      <td>0.339261</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.330500</td>\n",
              "      <td>0.338797</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1900</td>\n",
              "      <td>0.332800</td>\n",
              "      <td>0.337937</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.330500</td>\n",
              "      <td>0.337491</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=2025, training_loss=0.4109481860973217, metrics={'train_runtime': 10965.496, 'train_samples_per_second': 0.369, 'train_steps_per_second': 0.185, 'total_flos': 1638718768742400.0, 'train_loss': 0.4109481860973217, 'epoch': 3.0})"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "# Train!\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OyUwB0cVwtFK"
      },
      "source": [
        "## 6. Test the Fine-tuned Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S3j7X_oxwtFK",
        "outputId": "79f059a2-490b-4a91-d688-932586f5fd94"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üß™ Testing fine-tuned model...\n",
            "\n",
            "============================================================\n",
            "GENERATED EXPLANATION:\n",
            "============================================================\n",
            "### Instruction:\n",
            "Explain why this loan application was approved.\n",
            "\n",
            "### Input:\n",
            "Credit Score: 720\n",
            "Debt-to-Income Ratio: 28%\n",
            "Loan Amount: $25,000\n",
            "Annual Income: $85,000\n",
            "Employment Length: 5 years\n",
            "Delinquencies (2 yrs): 0\n",
            "Credit Inquiries (6 mo): 1\n",
            "\n",
            "### Response:\n",
            "Based on the information provided, the applicant has a strong credit history with no recent credit issues. Their debt-to-income ratio is very low at 28%, which indicates a good ability to manage debt payments. They have no recent delinquencies, and their employment history is stable. All these factors contribute to their approval for a $25,000 loan.\n",
            "\n",
            "In summary, the applicant's strong creditworthiness, manageable debt levels, and reliable employment history make them a suitable candidate for the $25,000 loan.\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# Test generation\n",
        "test_prompt = \"\"\"### Instruction:\n",
        "Explain why this loan application was approved.\n",
        "\n",
        "### Input:\n",
        "Credit Score: 720\n",
        "Debt-to-Income Ratio: 28%\n",
        "Loan Amount: $25,000\n",
        "Annual Income: $85,000\n",
        "Employment Length: 5 years\n",
        "Delinquencies (2 yrs): 0\n",
        "Credit Inquiries (6 mo): 1\n",
        "\n",
        "### Response:\n",
        "\"\"\"\n",
        "\n",
        "inputs = tokenizer(test_prompt, return_tensors=\"pt\").to(model.device)\n",
        "\n",
        "print(\"üß™ Testing fine-tuned model...\")\n",
        "with torch.no_grad():\n",
        "    outputs = model.generate(\n",
        "        **inputs,\n",
        "        max_new_tokens=200,\n",
        "        temperature=0.7,\n",
        "        do_sample=True,\n",
        "        top_p=0.9,\n",
        "        pad_token_id=tokenizer.eos_token_id\n",
        "    )\n",
        "\n",
        "response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"GENERATED EXPLANATION:\")\n",
        "print(\"=\"*60)\n",
        "print(response)\n",
        "print(\"=\"*60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZeOZCs6OwtFK"
      },
      "source": [
        "## 7. Save and Download Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mj7Y-TLawtFK",
        "outputId": "5d79ea47-4696-494c-fea9-5f7fac389f9e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üíæ Saving fine-tuned model...\n",
            "‚úÖ Model saved!\n",
            "  adding: granite-finetuned-final/ (stored 0%)\n",
            "  adding: granite-finetuned-final/special_tokens_map.json (deflated 79%)\n",
            "  adding: granite-finetuned-final/vocab.json (deflated 56%)\n",
            "  adding: granite-finetuned-final/adapter_config.json (deflated 57%)\n",
            "  adding: granite-finetuned-final/README.md (deflated 66%)\n",
            "  adding: granite-finetuned-final/tokenizer.json (deflated 80%)\n",
            "  adding: granite-finetuned-final/adapter_model.safetensors (deflated 7%)\n",
            "  adding: granite-finetuned-final/training_args.bin (deflated 54%)\n",
            "  adding: granite-finetuned-final/merges.txt (deflated 50%)\n",
            "  adding: granite-finetuned-final/tokenizer_config.json (deflated 95%)\n",
            "  adding: granite-finetuned-final/chat_template.jinja (deflated 79%)\n",
            "\n",
            "üì¶ Model packaged for download\n"
          ]
        }
      ],
      "source": [
        "# Save model\n",
        "print(\"üíæ Saving fine-tuned model...\")\n",
        "trainer.save_model(\"./granite-finetuned-final\")\n",
        "tokenizer.save_pretrained(\"./granite-finetuned-final\")\n",
        "print(\"‚úÖ Model saved!\")\n",
        "\n",
        "# Create zip for download\n",
        "!zip -r granite-finetuned-final.zip granite-finetuned-final/\n",
        "print(\"\\nüì¶ Model packaged for download\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 160
        },
        "id": "04Z8yfe6wtFK",
        "outputId": "6c59467d-13f8-432a-fc19-0b17ec39f13b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚¨áÔ∏è Downloading fine-tuned model...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_fd1ee7eb-d0b1-45e7-9d2f-88a82d75b312\", \"granite-finetuned-final.zip\", 3191872)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚úÖ Download started!\n",
            "\n",
            "To use locally:\n",
            "1. Extract granite-finetuned-final.zip\n",
            "2. Move to LendSafe/models/granite-finetuned/\n",
            "3. Run evaluation script\n"
          ]
        }
      ],
      "source": [
        "# Download the model\n",
        "from google.colab import files\n",
        "\n",
        "print(\"‚¨áÔ∏è Downloading fine-tuned model...\")\n",
        "files.download('granite-finetuned-final.zip')\n",
        "print(\"\\n‚úÖ Download started!\")\n",
        "print(\"\\nTo use locally:\")\n",
        "print(\"1. Extract granite-finetuned-final.zip\")\n",
        "print(\"2. Move to LendSafe/models/granite-finetuned/\")\n",
        "print(\"3. Run evaluation script\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lcr1TdEywtFL"
      },
      "source": [
        "## üéâ Done!\n",
        "\n",
        "Your Granite model is now fine-tuned for loan explanations!\n",
        "\n",
        "**Next steps:**\n",
        "1. Download the model zip file\n",
        "2. Extract and place in your local LendSafe project\n",
        "3. Run `python scripts/evaluate_model.py` to get metrics\n",
        "\n",
        "**Training Summary:**\n",
        "- Model: IBM Granite 4.0 H 350M\n",
        "- Method: LoRA (0.1% parameters trained)\n",
        "- Data: 1,500 loan explanation examples\n",
        "- Training time: ~15-30 minutes on T4 GPU\n",
        "- Cost: $0 (free Colab)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.0"
    },
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "73d32eca88c541ffbb59a0e944771f4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5ec04eecb2ef4681801ee1a329e5b21f",
              "IPY_MODEL_4c7ad38cb98349ad918f3b5b1a159813",
              "IPY_MODEL_2ccdf7a83bc14926928acfa50018fae2"
            ],
            "layout": "IPY_MODEL_1c89705ecd8344c48f57369046aaf647"
          }
        },
        "5ec04eecb2ef4681801ee1a329e5b21f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_920f9a09aaae4e29be51ebee8d689925",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_ab6a4a3a8a8343c381586467c8824e0a",
            "value": "Map:‚Äá100%"
          }
        },
        "4c7ad38cb98349ad918f3b5b1a159813": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_efd45863c32a4aa7a8a13b4c1d0a0145",
            "max": 1500,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0e9bd3352b014501aa0e37ae4d0cfd4e",
            "value": 1500
          }
        },
        "2ccdf7a83bc14926928acfa50018fae2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_715dacc33545419288ae2f457e7c344e",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_a04625562e5c4584bda15fa41afe6655",
            "value": "‚Äá1500/1500‚Äá[00:02&lt;00:00,‚Äá637.29‚Äáexamples/s]"
          }
        },
        "1c89705ecd8344c48f57369046aaf647": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "920f9a09aaae4e29be51ebee8d689925": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab6a4a3a8a8343c381586467c8824e0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "efd45863c32a4aa7a8a13b4c1d0a0145": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e9bd3352b014501aa0e37ae4d0cfd4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "715dacc33545419288ae2f457e7c344e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a04625562e5c4584bda15fa41afe6655": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}