# LendSafe: Local Loan Decision Explainer

## ğŸ¯ Project Overview

**LendSafe** is an AI-powered loan decision explanation system that runs entirely locally, providing regulatory-compliant adverse action notices and human-readable explanations for loan approvals/rejections. Built to address the critical need for explainable AI in financial services while maintaining data privacy.

### Why This Project Matters
- **Regulatory Compliance**: Addresses FCRA/ECOA requirements for explaining credit decisions
- **Privacy-First**: 100% local processing - no data leaves the institution
- **Cost-Effective**: No API costs, runs on commodity hardware (M2 MacBook Air)
- **Explainable AI**: Every decision backed by clear reasoning and regulatory citations

### Target Use Cases
- Credit unions and community banks needing affordable compliance solutions
- Fintech lenders building transparent lending platforms
- Model risk management teams requiring explainable models
- Financial institutions migrating to AI-powered decisioning

---

## ğŸ—ï¸ Architecture

### System Components
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    LendSafe Architecture                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚  â”‚   Streamlit  â”‚ â—„â”€â”€â”€â”€â”€â–º â”‚  Loan Decision  â”‚              â”‚
â”‚  â”‚   Frontend   â”‚         â”‚     Engine      â”‚              â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â”‚                                     â”‚                        â”‚
â”‚                                     â–¼                        â”‚
â”‚                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚
â”‚                          â”‚  IBM Granite     â”‚               â”‚
â”‚                          â”‚  4.0 H 350M      â”‚               â”‚
â”‚                          â”‚  (Fine-tuned)    â”‚               â”‚
â”‚                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
â”‚                                   â”‚                          â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚                    â–¼              â–¼              â–¼          â”‚
â”‚          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚          â”‚  Risk Score â”‚  â”‚   RAG    â”‚  â”‚  Adverse     â”‚  â”‚
â”‚          â”‚  Calculator â”‚  â”‚  System  â”‚  â”‚  Action      â”‚  â”‚
â”‚          â”‚             â”‚  â”‚          â”‚  â”‚  Generator   â”‚  â”‚
â”‚          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                 â”‚                            â”‚
â”‚                                 â–¼                            â”‚
â”‚                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚
â”‚                        â”‚   ChromaDB      â”‚                  â”‚
â”‚                        â”‚ (Regulatory     â”‚                  â”‚
â”‚                        â”‚  Knowledge)     â”‚                  â”‚
â”‚                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚
â”‚                                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ› ï¸ Tech Stack

### Core Components (All Free & Open Source)

| Component | Technology | Why This Choice |
|-----------|-----------|-----------------|
| **LLM** | IBM Granite 4.0 H 350M | Tiny (350M params), enterprise-focused, <2GB RAM |
| **Fine-tuning** | Hugging Face PEFT (LoRA) | Parameter-efficient, Mac-friendly |
| **Vector DB** | ChromaDB | Local storage, no cloud dependency |
| **Framework** | LangChain | Standard RAG implementation |
| **Frontend** | Streamlit | Rapid prototyping, free deployment |
| **Risk Model** | Scikit-learn / XGBoost | Industry-standard, interpretable |
| **Package Manager** | uv | 10-100x faster than pip, Rust-based |
| **Deployment** | Streamlit Cloud | Free tier, easy sharing |

### Why IBM Granite 4.0 H 350M?

1. **Tiny but Mighty**: 350M parameters vs 3B+ in other models
   - <2GB RAM on M2 MacBook Air
   - Inference: <500ms per request
   - No GPU needed

2. **Enterprise-Grade**: Built by IBM Research
   - Pre-trained on financial/business documents
   - Better regulatory language understanding
   - Apache 2.0 license

3. **Finance-Optimized**: Handles structured data naturally

### Why uv Package Manager?

- **Speed**: 10-100x faster than pip
- **Reliability**: Rust-based, deterministic
- **Modern**: Drop-in pip replacement
- **Zero-config**: Works out of the box

---

## ğŸ“‹ 4-Week Development Roadmap

### Week 1: Foundation & Data Pipeline
**Deliverables:**
- [ ] Development environment configured with uv
- [ ] Lending Club dataset cleaned
- [ ] Baseline XGBoost risk model trained
- [ ] IBM Granite 4.0 H 350M tested
- [ ] 100 synthetic loan explanations

**Setup:**
```bash
# Install uv
curl -LsSf https://astral.sh/uv/install.sh | sh

# Create project
uv venv
source .venv/bin/activate

# Install dependencies (blazing fast!)
uv pip install torch transformers accelerate peft
uv pip install pandas scikit-learn xgboost
uv pip install langchain chromadb streamlit
```

### Week 2: LLM Fine-tuning
**Deliverables:**
- [ ] 1000+ training examples
- [ ] Fine-tuned Granite with LoRA
- [ ] Evaluation metrics (ROUGE, BERTScore)

**Expected Performance on M2:**
- Memory: ~6-8GB RAM
- Training: 2-3 hours for 1000 examples
- Inference: <500ms per application

### Week 3: RAG System & Compliance
**Deliverables:**
- [ ] ChromaDB with FCRA/ECOA regulations
- [ ] RAG pipeline with citations
- [ ] Adverse action notice generator (PDF)

### Week 4: Integration & Demo
**Deliverables:**
- [ ] Streamlit dashboard
- [ ] Demo video (3-5 minutes)
- [ ] GitHub repo + README
- [ ] Medium article draft

---

## ğŸš€ Quick Start
```bash
# 1. Install uv
curl -LsSf https://astral.sh/uv/install.sh | sh

# 2. Clone and setup
git clone https://github.com/yourusername/lendsafe.git
cd lendsafe
uv venv
source .venv/bin/activate

# 3. Install dependencies
uv pip install -r requirements.txt

# 4. Download Granite
python scripts/download_model.py

# 5. Run app
streamlit run app.py
```

---

## ğŸ’» Key Code Examples

### Fine-tuning Script
```python
from transformers import AutoModelForCausalLM, AutoTokenizer
from peft import LoraConfig, get_peft_model

MODEL_ID = "ibm-granite/granite-4.0-h-350m"

# Load model
model = AutoModelForCausalLM.from_pretrained(
    MODEL_ID,
    torch_dtype=torch.float16,
    device_map="auto"
)

# LoRA config
lora_config = LoraConfig(
    r=16,
    lora_alpha=32,
    target_modules=["q_proj", "v_proj", "k_proj", "o_proj"],
    lora_dropout=0.05,
    task_type="CAUSAL_LM"
)

# Apply LoRA (only 0.15% params trained!)
model = get_peft_model(model, lora_config)
```

### Inference
```python
class GraniteLoanExplainer:
    def explain_decision(self, loan_data, decision):
        prompt = f"""### Instruction:
Explain why this loan was {decision}.

### Input:
Credit Score: {loan_data['credit_score']}
DTI: {loan_data['dti_ratio']}%
Amount: ${loan_data['loan_amount']:,}

### Response:
"""
        outputs = self.model.generate(**inputs, max_new_tokens=200)
        return self.tokenizer.decode(outputs[0])
```

---

## ğŸ¯ Pitch Strategy

### Elevator Pitch
*"LendSafe uses IBM's enterprise-grade Granite AI to generate FCRA-compliant loan explanations entirely on your infrastructure. Zero API costs, complete privacy, runs on a laptop. Built for credit unions who need compliance without cloud dependency."*

### Target Companies
1. **Navy Federal Credit Union** - Follow up on your interview!
2. **Upstart, SoFi, Affirm** - AI-native lenders
3. **Regional banks** - Model risk teams
4. **Credit bureaus** - White-label solution

### Demo Script (5 min)
1. **Problem** (30s): $X billion in regulatory fines
2. **Solution** (30s): Show architecture
3. **Live Demo** (3 min): Upload â†’ Explain â†’ PDF in <3 seconds
4. **Tech** (30s): "IBM Granite + M2 MacBook + <2GB RAM"
5. **Value** (30s): $0/inference vs $10K+/month APIs
6. **CTA** (30s): "Built in 4 weeks with $0 budget"

---

## ğŸ“Š Success Metrics

### Technical
- âœ… <2GB RAM usage
- âœ… <3 seconds inference
- âœ… 90%+ ROUGE-L score
- âœ… 100% FCRA compliance

### Business
- ğŸ¯ 5+ company pilots
- ğŸ¯ 2+ interviews from demo
- ğŸ¯ 1000+ GitHub stars

---

## ğŸ“¦ Project Structure
```
lendsafe/
â”œâ”€â”€ .venv/                      # uv virtual environment
â”œâ”€â”€ pyproject.toml              # Modern Python config
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ app.py                      # Streamlit app
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/
â”‚   â”œâ”€â”€ processed/
â”‚   â””â”€â”€ synthetic/
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ risk_model/
â”‚   â””â”€â”€ granite-lendsafe/       # Fine-tuned weights
â”œâ”€â”€ chromadb/                   # Vector DB
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ download_model.py
â”‚   â”œâ”€â”€ finetune_granite.py
â”‚   â””â”€â”€ build_chroma_db.py
â””â”€â”€ src/
    â”œâ”€â”€ llm_explainer.py
    â”œâ”€â”€ rag_pipeline.py
    â””â”€â”€ notice_generator.py
```

---

## ğŸ” Regulatory Compliance

### FCRA Requirements âœ…
- Section 615: Adverse action notices
- Section 609: Disclosure of information
- Section 623: Accuracy and completeness

### ECOA Requirements âœ…
- Regulation B: Notification
- 12 CFR 1002.9: Specific reasons
- Plain language: 8th-grade level

---

## ğŸš§ Future Enhancements

**Phase 2:**
- Multi-language support
- Voice explanations
- Counterfactual analysis

**Phase 3:**
- API access
- Multi-tenant support
- Kubernetes deployment

**Phase 4:**
- Drift detection
- Fairness metrics
- Causal inference

---

## ğŸ“š Resources

- [IBM Granite Models](https://huggingface.co/ibm-granite)
- [uv Documentation](https://github.com/astral-sh/uv)
- [PEFT Guide](https://huggingface.co/docs/peft)
- [FCRA Text](https://www.ftc.gov/enforcement/statutes/fair-credit-reporting-act)

---

## âš¡ Quick Start Checklist

**Week 1:**
- [ ] Install uv
- [ ] Download Lending Club data
- [ ] Test Granite model

**Week 2:**
- [ ] Generate training data
- [ ] Fine-tune with LoRA

**Week 3:**
- [ ] Build ChromaDB
- [ ] Implement RAG

**Week 4:**
- [ ] Streamlit app
- [ ] Demo video
- [ ] GitHub launch

---

**Built with:**
- Zero dollars ğŸ’°
- M2 MacBook Air ğŸ’»
- 4 weeks â°
- IBM Granite ğŸ¤–

**Perfect for:**
- Navy Federal follow-up interview
- Fintech job applications
- Portfolio differentiation
- Learning regulatory ML

---

*Ready to build LendSafe and land that job? Let's go! ğŸš€*

**File saved to:** `/Users/atharvadeshmukh/Desktop/lendsafe_claude.md`